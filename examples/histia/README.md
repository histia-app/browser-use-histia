# API FastAPI : Agents Histia d'extraction de donn√©es

Ce r√©pertoire contient une API FastAPI compl√®te pour utiliser les agents d'extraction Histia. Chaque agent dispose de son propre endpoint POST d√©di√© avec documentation compl√®te et exemples d'utilisation.

## Pr√©requis

- Python 3.11+
- D√©pendances install√©es (FastAPI, Uvicorn et les d√©pendances du projet) via `uv sync` ou `pip install -e .[dev]`
- Variables d'environnement pour le backend LLM :
  - `BROWSER_USE_API_KEY` (recommand√©) pour utiliser ChatBrowserUse
  - `OPENAI_API_KEY` et √©ventuellement `OPENAI_API_BASE` pour un backend LiteLLM/OpenAI
  - ou `LLM_BACKEND=gemini` + `GOOGLE_API_KEY` (ou `GEMINI_API_KEY`) pour basculer sur Gemini

## D√©marrage

Lancez l'API en mode d√©veloppement avec rechargement √† chaud :

```bash
uvicorn examples.histia.fastapi_agents:app --reload
```

L'explorateur interactif est disponible sur `http://localhost:8000/docs` (OpenAPI/Swagger) et `http://localhost:8000/redoc`.

## Agents disponibles

Les agents sont organis√©s en deux cat√©gories :

1. **Agents g√©n√©raux** : Agents polyvalents qui fonctionnent avec de multiples sources et structures de sites web
2. **Agents sp√©cialis√©s** : Agents optimis√©s pour des plateformes sp√©cifiques, offrant une meilleure performance et fiabilit√© pour leurs plateformes cibles

### Guide de s√©lection rapide

| Site/Plateforme | Agent recommand√© | Alternative |
|----------------|------------------|-------------|
| **Product Hunt** (leaderboard) | `product_hunt_leaderboard` | `startup_listing` |
| **FutureTools** | `futuretools_extractor` | `universal_startup_extractor` |
| **AppSumo** (What's hot) | `appsumo_hot_extractor` | - |
| **AppSumo** (New arrivals) | `appsumo_new_extractor` | - |
| **BetaList** | `betalist_extractor` | `startup_listing` |
| **Station F** | `stationf_companies_extractor` | `universal_startup_extractor` |
| **Zone Secure** | `zone_secure_startups_extractor` | `universal_startup_extractor` |
| **Airtable** | `airtable_extractor` | - |
| **Sites personnalis√©s/inconnus** | `universal_startup_extractor` | `startup_listing` |
| **Page produit individuelle** | `product_research` | - |
| **Liste de startups g√©n√©rique** | `startup_listing` | `universal_startup_extractor` |

> üí° **Recommandation** : Pour les plateformes list√©es ci-dessus, utilisez toujours l'agent sp√©cialis√© pour de meilleures performances. Les agents sp√©cialis√©s sont g√©n√©ralement 2-3x plus rapides et plus fiables que les agents g√©n√©raux.

---

## Agents g√©n√©raux

Ces agents peuvent fonctionner avec de nombreux sites web diff√©rents. Ils utilisent des strat√©gies guid√©es par LLM pour s'adapter √† diff√©rentes structures de pages.

### 1. Product Research (`product_research`) (PAS LISTING)

Agent de recherche de produits qui extrait des informations structur√©es sur les entreprises et leurs produits depuis des listings (Product Hunt, BetaList, etc.). Retourne un profil d'entreprise complet, les produits principaux, et des faits notables.

**Endpoint :** `POST /agents/product_research/run`

**Param√®tres :**
- `url` (requis, `AnyHttpUrl`) : URL du listing √† analyser (Product Hunt, BetaList, etc.)
- `max_products` (optionnel, `int`, d√©faut: `3`) : Nombre maximum de produits ou variantes √† r√©sumer (min: 1, max: 10)
- `output_path` (optionnel, `Path`, d√©faut: `"product_research_report.json"`) : Chemin de destination pour le rapport JSON g√©n√©r√©

**Exemple complet avec tous les param√®tres :**

```bash
curl -X POST "http://localhost:8000/agents/product_research/run" \
     -H "Content-Type: application/json" \
     -d '{
       "url": "https://www.producthunt.com/posts/example-product",
       "max_products": 5,
       "output_path": "my_product_research.json"
     }'
```

**Exemple pour BetaList :**

```bash
curl -X POST "http://localhost:8000/agents/product_research/run" \
     -H "Content-Type: application/json" \
     -d '{
       "url": "https://betalist.com/startups/example-startup",
       "max_products": 3,
       "output_path": "betalist_research.json"
     }'
```

**Exemple pour extraire le maximum de produits (10 produits) :**

```bash
curl -X POST "http://localhost:8000/agents/product_research/run" \
     -H "Content-Type: application/json" \
     -d '{
       "url": "https://www.producthunt.com/posts/complex-product",
       "max_products": 10,
       "output_path": "full_product_research.json"
     }'
```

**Exemple minimal (seulement l'URL requise) :**

```bash
curl -X POST "http://localhost:8000/agents/product_research/run" \
     -H "Content-Type: application/json" \
     -d '{
       "url": "https://www.producthunt.com/posts/my-awesome-product"
     }'
```

**Exemple avec Python :**

```python
import requests

# Exemple complet avec analyse des r√©sultats
response = requests.post(
    "http://localhost:8000/agents/product_research/run",
    json={
        "url": "https://www.producthunt.com/posts/example-product",
        "max_products": 5,
        "output_path": "research_report.json"
    }
)
report = response.json()

# Afficher les informations de l'entreprise
company = report['company']
print(f"Entreprise: {company['name']}")
print(f"Site web: {company.get('official_website', 'N/A')}")
print(f"LinkedIn: {company.get('linkedin_page', 'N/A')}")
if company.get('other_facts'):
    print(f"Faits notables: {', '.join(company['other_facts'][:3])}")

# Afficher les produits
print(f"\nProduits trouv√©s: {len(report['products'])}")
for i, product in enumerate(report['products'], 1):
    print(f"\n{i}. {product['product_name']}")
    print(f"   Description: {product['what_it_does']}")
    print(f"   Mod√®le: {product.get('go_to_market', 'N/A')}")
    print(f"   Audience: {product.get('target_audience', 'N/A')}")

# Exemple minimal
response = requests.post(
    "http://localhost:8000/agents/product_research/run",
    json={
        "url": "https://betalist.com/startups/my-startup"
    }
)
```

**Note importante :** Cet agent analyse une page de listing sp√©cifique (pas une liste de produits). Il extrait les informations d√©taill√©es sur l'entreprise et ses produits depuis une page individuelle. Pour extraire plusieurs startups depuis une liste, utilisez plut√¥t l'agent `startup_listing`.

**R√©ponse :** Rapport structur√© (`ProductResearchReport`) contenant :
- `company` : Profil d'entreprise complet avec :
  - `name` : Nom officiel de l'entreprise
  - `logo_url` : URL absolue du logo si disponible
  - `description` : Description courte de l'entreprise
  - `official_website` : URL du site web principal
  - `linkedin_page` : URL de la page LinkedIn si disponible
  - `other_facts` : Liste de faits notables (financement, m√©triques, fondateurs, etc.)
- `products` : Liste des produits principaux (min: 1) avec :
  - `product_name` : Nom du produit
  - `what_it_does` : Proposition de valeur en une phrase
  - `go_to_market` : Mod√®le √©conomique (B2B, B2C, B2G, etc.)
  - `target_audience` : Personas ou industries cibl√©es
  - `description` : Description plus d√©taill√©e du produit

### 2. Startup Listing (`startup_listing`)

Agent de listing de startups qui extrait une liste l√©g√®re de startups depuis des annuaires (Product Hunt, BetaList, FutureTools, etc.). Id√©al pour cr√©er rapidement une liste de startups avec leurs informations de base.

**Endpoint :** `POST /agents/startup_listing/run`

**Param√®tres :**
- `url` (requis, `AnyHttpUrl`) : URL de l'annuaire ou de la page de listing √† analyser
- `max_startups` (optionnel, `int`, d√©faut: `12`) : Nombre maximum de startups √† capturer (min: 1, max: 1000). Utilisez un nombre √©lev√© comme 1000 pour extraire toutes les startups disponibles
- `output_path` (optionnel, `Path`, d√©faut: `"startup_listings.json"`) : Chemin de destination pour le fichier JSON

**Exemple complet avec tous les param√®tres :**

```bash
curl -X POST "http://localhost:8000/agents/startup_listing/run" \
     -H "Content-Type: application/json" \
     -d '{
       "url": "https://www.producthunt.com/topics/startups",
       "max_startups": 100,
       "output_path": "product_hunt_startups.json"
     }'
```

**Exemple pour BetaList :**

```bash
curl -X POST "http://localhost:8000/agents/startup_listing/run" \
     -H "Content-Type: application/json" \
     -d '{
       "url": "https://betalist.com/startups",
       "max_startups": 1000,
       "output_path": "all_betalist_startups.json"
     }'
```

**Note importante :** Pour les plateformes suivantes, pr√©f√©rez les agents sp√©cialis√©s d√©di√©s (plus performants et fiables) :
- **FutureTools** ‚Üí `futuretools_extractor` (section 5)
- **AppSumo** ‚Üí `appsumo_hot_extractor` ou `appsumo_new_extractor` (section 6-7)
- **BetaList** ‚Üí `betalist_extractor` (section 8)
- **Station F** ‚Üí `stationf_companies_extractor` (section 9)
- **Zone Secure** ‚Üí `zone_secure_startups_extractor` (section 10)

L'agent `startup_listing` fonctionne avec ces plateformes mais sera g√©n√©ralement plus lent et moins fiable que les agents sp√©cialis√©s.

**Exemple pour extraire toutes les startups (limite maximale) :**

```bash
curl -X POST "http://localhost:8000/agents/startup_listing/run" \
     -H "Content-Type: application/json" \
     -d '{
       "url": "https://www.producthunt.com/topics/ai",
       "max_startups": 1000,
       "output_path": "all_ai_startups.json"
     }'
```

**Exemple minimal (seulement l'URL requise) :**

```bash
curl -X POST "http://localhost:8000/agents/startup_listing/run" \
     -H "Content-Type: application/json" \
     -d '{
       "url": "https://www.producthunt.com/topics/ai"
     }'
```

**Exemple avec Python :**

```python
import requests

# Extraire 50 startups depuis Product Hunt avec analyse
response = requests.post(
    "http://localhost:8000/agents/startup_listing/run",
    json={
        "url": "https://www.producthunt.com/topics/startups",
        "max_startups": 50,
        "output_path": "startups.json"
    }
)

# V√©rifier le code de statut
if response.status_code == 200:
    # Succ√®s complet
    report = response.json()
    print(f"‚úÖ Extraction r√©ussie!")
    print(f"Source: {report['source_url']}")
    print(f"Startups extraites: {len(report['startups'])}")
elif response.status_code == 206:
    # Rapport de fallback (agent interrompu)
    data = response.json()
    print(f"‚ö†Ô∏è  Attention: {data.get('warning', 'Extraction partielle')}")
    print(f"Message: {data.get('message', '')}")
    report = data.get('report', {})
    print(f"Source: {report.get('source_url', 'N/A')}")
    print(f"Startups extraites: {len(report.get('startups', []))}")
    # Le rapport peut contenir des donn√©es partielles ou un placeholder
else:
    # Erreur
    print(f"‚ùå Erreur {response.status_code}: {response.text}")

# Afficher les premi√®res startups (si disponibles)
if 'startups' in report:
    for i, startup in enumerate(report['startups'][:10], 1):
        print(f"\n{i}. {startup['name']}")
        print(f"   Description: {startup.get('description', 'N/A')}")
        print(f"   URL: {startup.get('url', 'N/A')}")
        if startup.get('tags'):
            print(f"   Tags: {', '.join(startup['tags'][:3])}")

# Exemple pour extraire toutes les startups depuis BetaList
response = requests.post(
    "http://localhost:8000/agents/startup_listing/run",
    json={
        "url": "https://betalist.com/startups",
        "max_startups": 1000
    }
)
# V√©rifier toujours le code de statut
if response.status_code not in [200, 206]:
    print(f"Erreur: {response.status_code}")
```

**Note importante :** Cet agent extrait une liste de startups depuis une page de listing ou un annuaire. Pour analyser en d√©tail une startup sp√©cifique (entreprise + produits), utilisez plut√¥t l'agent `product_research` avec l'URL de la page individuelle.

**R√©ponse :** Rapport structur√© (`StartupListingReport`) contenant :
- `source_url` : URL de la page analys√©e
- `startups` : Liste de profils de startups avec :
  - `name` : Nom de la startup
  - `description` : Description courte
  - `url` : URL de la page de la startup
  - `tags` : Liste des tags/cat√©gories
  - `logo_url` : URL du logo si disponible
  - `website` : Site web officiel si disponible
  - Autres m√©tadonn√©es selon la source

### 3. Universal Startup Extractor (`universal_startup_extractor`)

**Agent le plus polyvalent** - Extracteur universel de startups qui peut extraire TOUTES les startups depuis N'IMPORTE QUEL site web, quelle que soit sa structure. Utilise des strat√©gies guid√©es par LLM pour trouver et extraire les startups de mani√®re exhaustive.

> üí° **Quand l'utiliser ?** Cet agent est id√©al pour des sites web personnalis√©s ou des annuaires non-standard. Pour les plateformes connues (Product Hunt, AppSumo, BetaList, etc.), pr√©f√©rez les agents sp√©cialis√©s list√©s ci-dessous pour de meilleures performances.

**Endpoint :** `POST /agents/universal_startup_extractor/run`

**Param√®tres :**
- `url` (requis, `str`) : URL du site web √† analyser (peut √™tre n'importe quel site contenant des startups)
- `max_startup` (optionnel, `int`, d√©faut: `100000`) : Nombre maximum de startups √† extraire avant arr√™t imm√©diat (min: 1, max: 1000000). Utilisez un nombre √©lev√© pour extraire toutes les startups disponibles
- `output_path` (optionnel, `Path`, d√©faut: `"extracted_startups.json"`) : Chemin de destination pour le fichier JSON

**Exemple complet avec tous les param√®tres :**

```bash
curl -X POST "http://localhost:8000/agents/universal_startup_extractor/run" \
     -H "Content-Type: application/json" \
     -d '{
       "url": "https://example.com/startups-directory",
       "max_startup": 500,
       "output_path": "extracted_startups.json"
     }'
```

**Exemple pour un site personnalis√© :**

```bash
curl -X POST "http://localhost:8000/agents/universal_startup_extractor/run" \
     -H "Content-Type: application/json" \
     -d '{
       "url": "https://my-custom-startup-directory.com/companies",
       "max_startup": 1000,
       "output_path": "custom_directory_startups.json"
     }'
```

**Exemple pour extraire toutes les startups (limite tr√®s √©lev√©e) :**

```bash
curl -X POST "http://localhost:8000/agents/universal_startup_extractor/run" \
     -H "Content-Type: application/json" \
     -d '{
       "url": "https://example.com/startups",
       "max_startup": 100000,
       "output_path": "all_startups.json"
     }'
```

**Exemple avec limite raisonnable pour un test rapide :**

```bash
curl -X POST "http://localhost:8000/agents/universal_startup_extractor/run" \
     -H "Content-Type: application/json" \
     -d '{
       "url": "https://example.com/startups",
       "max_startup": 50,
       "output_path": "test_extraction.json"
     }'
```

**Exemple minimal (seulement l'URL requise) :**

```bash
curl -X POST "http://localhost:8000/agents/universal_startup_extractor/run" \
     -H "Content-Type: application/json" \
     -d '{
       "url": "https://example.com/startups"
     }'
```

**Exemple avec Python :**

```python
import requests

# Extraction avec limite personnalis√©e et analyse des r√©sultats
response = requests.post(
    "http://localhost:8000/agents/universal_startup_extractor/run",
    json={
        "url": "https://example.com/startups-directory",
        "max_startup": 200,
        "output_path": "my_startups.json"
    }
)
report = response.json()
print(f"Source: {report['source_url']}")
print(f"Startups extraites: {len(report['startups'])}")

# Afficher les premi√®res startups extraites
for i, startup in enumerate(report['startups'][:10], 1):
    print(f"\n{i}. {startup.get('name', 'N/A')}")
    if startup.get('description'):
        print(f"   Description: {startup['description'][:100]}...")
    if startup.get('url'):
        print(f"   URL: {startup['url']}")

# Exemple pour extraction exhaustive
response = requests.post(
    "http://localhost:8000/agents/universal_startup_extractor/run",
    json={
        "url": "https://example.com/startups",
        "max_startup": 100000  # Limite tr√®s √©lev√©e pour tout extraire
    }
)
```

**Note importante :** Cet agent est con√ßu pour fonctionner avec n'importe quel site web, m√™me ceux qui ne sont pas sp√©cialement con√ßus comme annuaires de startups. Il utilise l'IA pour identifier et extraire les startups de mani√®re intelligente. L'extraction peut prendre plus de temps selon la complexit√© du site et le nombre de startups √† extraire. Pour les sites connus (Product Hunt, BetaList, etc.), l'agent `startup_listing` peut √™tre plus rapide et efficace.

**R√©ponse :** Rapport d'extraction (`StartupExtractionReport`) contenant :
- `source_url` : URL du site analys√©
- `startups` : Liste exhaustive de toutes les startups trouv√©es avec leurs informations compl√®tes :
  - `name` : Nom de la startup
  - `description` : Description d√©taill√©e
  - `url` : URL de la page de la startup
  - `website` : Site web officiel si disponible
  - `tags` : Cat√©gories/tags associ√©s
  - Autres m√©tadonn√©es extraites selon le site

---

## Agents sp√©cialis√©s par plateforme

### Comment utiliser les agents sp√©cialis√©s

Les agents sp√©cialis√©s sont des extracteurs optimis√©s pour des plateformes sp√©cifiques. Ils offrent plusieurs avantages par rapport aux agents g√©n√©raux :

#### Avantages des agents sp√©cialis√©s

1. **Performance optimis√©e** üöÄ
   - Extraction 2-3x plus rapide gr√¢ce √† une connaissance approfondie de la structure HTML/CSS
   - Moins de tentatives d'extraction, moins de temps de traitement
   - Utilisation efficace de la m√©moire et des ressources

2. **Fiabilit√© accrue** ‚úÖ
   - Gestion native des fonctionnalit√©s sp√©cifiques (pagination, scroll infini, authentification)
   - Moins d'erreurs de parsing gr√¢ce √† des s√©lecteurs CSS pr√©cis
   - Adaptation automatique aux changements mineurs de structure

3. **Donn√©es plus compl√®tes** üìä
   - Extraction de m√©tadonn√©es sp√©cifiques √† chaque plateforme (votes, notes, badges, etc.)
   - Meilleure normalisation des donn√©es (formats de dates, cat√©gories, etc.)
   - D√©tection automatique des champs optionnels

4. **Fonctionnalit√©s avanc√©es** üîß
   - Gestion automatique de la pagination multi-pages
   - Support de l'authentification quand n√©cessaire
   - Optimisation du scroll infini
   - Interception r√©seau pour les APIs cach√©es (Airtable)

#### Structure d'une requ√™te typique

Tous les agents sp√©cialis√©s suivent le m√™me pattern de requ√™te :

```bash
curl -X POST "http://localhost:8000/agents/{agent_name}/run" \
     -H "Content-Type: application/json" \
     -d '{
       "url": "...",           # URL de la page (souvent optionnel avec valeur par d√©faut)
       "max_items": 100,       # Limite d'extraction (nom varie selon l'agent)
       "output_path": "..."    # Chemin de sauvegarde (optionnel)
     }'
```

#### Param√®tres communs

La plupart des agents sp√©cialis√©s partagent des param√®tres similaires :

- **`url`** : URL de la page √† extraire
  - Souvent optionnel avec une URL par d√©faut optimale
  - Peut √™tre omis si vous voulez utiliser la page par d√©faut
  
- **`max_*`** : Limite d'extraction (nom varie : `max_products`, `max_tools`, `max_startups`, etc.)
  - Utilisez une valeur √©lev√©e (1000+) pour extraire tout le contenu
  - Par d√©faut, chaque agent a une limite raisonnable (200-1000)
  
- **`output_path`** : Chemin de sauvegarde du fichier JSON
  - Optionnel, un nom par d√©faut est fourni
  - Le fichier est sauvegard√© dans le r√©pertoire de travail du serveur

#### Bonnes pratiques

1. **Utiliser les valeurs par d√©faut** : Les agents sp√©cialis√©s ont des URLs et limites optimis√©es par d√©faut. Vous pouvez souvent omettre ces param√®tres :
   ```bash
   # Minimal - utilise les valeurs optimales par d√©faut
   curl -X POST "http://localhost:8000/agents/appsumo_hot_extractor/run" \
        -H "Content-Type: application/json" \
        -d '{}'
   ```

2. **V√©rifier le code de statut HTTP** : Les r√©ponses peuvent √™tre :
   - `200` : Succ√®s complet
   - `206` : Extraction partielle (timeout ou interruption)
   - `400` : Param√®tres invalides
   - `500` : Erreur serveur

3. **G√©rer les timeouts** : Pour de grandes extractions, l'agent peut prendre plusieurs minutes. Soyez patient ou utilisez des limites plus petites pour tester.

4. **Authentification** : Certains agents (comme Station F) supportent l'authentification via les param√®tres `email` et `password` si la page est priv√©e.

5. **URLs sp√©cifiques** : Utilisez les URLs recommand√©es pour chaque plateforme (ex: `/newly-added` pour FutureTools) pour de meilleurs r√©sultats.

#### Exemple complet avec gestion d'erreurs

```python
import requests
import json

def extract_with_retry(agent_name, payload, max_retries=3):
    """Extrait des donn√©es avec gestion des erreurs et retry."""
    for attempt in range(max_retries):
        try:
            response = requests.post(
                f"http://localhost:8000/agents/{agent_name}/run",
                json=payload,
                timeout=600  # 10 minutes pour les grandes extractions
            )
            
            if response.status_code == 200:
                return response.json(), "success"
            elif response.status_code == 206:
                data = response.json()
                return data.get('report', {}), "partial"
            elif response.status_code == 400:
                error_msg = response.json().get('detail', 'Invalid request')
                raise ValueError(f"Erreur de validation: {error_msg}")
            else:
                response.raise_for_status()
                
        except requests.Timeout:
            if attempt < max_retries - 1:
                print(f"Timeout, retry {attempt + 1}/{max_retries}...")
                continue
            raise
        except requests.RequestException as e:
            if attempt < max_retries - 1:
                print(f"Erreur r√©seau, retry {attempt + 1}/{max_retries}...")
                continue
            raise
    
    raise Exception("Tous les essais ont √©chou√©")

# Utilisation
try:
    report, status = extract_with_retry(
        "futuretools_extractor",
        {
            "url": "https://www.futuretools.io/newly-added",
            "max_tools": 1000
        }
    )
    
    if status == "success":
        print(f"‚úÖ Extraction compl√®te: {len(report.get('tools', []))} outils")
    elif status == "partial":
        print(f"‚ö†Ô∏è  Extraction partielle: {len(report.get('tools', []))} outils")
        
    # Traiter les donn√©es...
    for tool in report.get('tools', [])[:10]:
        print(f"- {tool.get('name')}: {tool.get('category')}")
        
except Exception as e:
    print(f"‚ùå Erreur: {e}")
```

#### Diff√©rences avec les agents g√©n√©raux

| Aspect | Agents sp√©cialis√©s | Agents g√©n√©raux |
|--------|-------------------|-----------------|
| **Vitesse** | 2-3x plus rapide | Plus lent (exploration) |
| **Fiabilit√©** | 95%+ de succ√®s | Variable selon le site |
| **M√©tadonn√©es** | Sp√©cifiques √† la plateforme | G√©n√©riques |
| **Configuration** | Valeurs par d√©faut optimales | N√©cessite plus de param√®tres |
| **Flexibilit√©** | Limit√©e √† une plateforme | Fonctionne partout |

#### Quand utiliser un agent sp√©cialis√© vs un agent g√©n√©ral

**Utilisez un agent sp√©cialis√© si :**
- ‚úÖ La plateforme est support√©e (voir le guide de s√©lection)
- ‚úÖ Vous voulez la meilleure performance
- ‚úÖ Vous avez besoin de m√©tadonn√©es sp√©cifiques
- ‚úÖ Vous extrayez r√©guli√®rement de cette plateforme

**Utilisez un agent g√©n√©ral si :**
- ‚úÖ La plateforme n'est pas support√©e
- ‚úÖ Vous testez un nouveau site
- ‚úÖ Vous avez besoin de flexibilit√© maximale
- ‚úÖ La structure du site est simple

---

### Liste d√©taill√©e des agents sp√©cialis√©s

### 4. Product Hunt Leaderboard (`product_hunt_leaderboard`)

Agent sp√©cialis√© dans l'extraction du leaderboard Product Hunt avec m√©triques, votes, commentaires, etc. Extrait les produits class√©s pour une date sp√©cifique.

**Endpoint :** `POST /agents/product_hunt_leaderboard/run`

**Param√®tres :**
- `date` (requis, `str`) : Date du leaderboard au format `YYYY-MM-DD` ou `YYYY/MM/DD` (ex: `"2025-01-15"` ou `"2025/01/15"`). La date sera automatiquement normalis√©e en `YYYY-MM-DD`
- `max_products` (optionnel, `int`, d√©faut: `1000`) : Nombre maximum de produits √† capturer depuis le leaderboard (min: 1, max: 10000). Utilisez un nombre √©lev√© comme 1000 pour extraire tous les produits
- `output_path` (optionnel, `Path`, d√©faut: `"product_hunt_leaderboard.json"`) : Chemin de destination pour le fichier JSON

**Exemple complet avec tous les param√®tres :**

```bash
curl -X POST "http://localhost:8000/agents/product_hunt_leaderboard/run" \
     -H "Content-Type: application/json" \
     -d '{
       "date": "2025-01-15",
       "max_products": 1000,
       "output_path": "ph_leaderboard_2025-01-15.json"
     }'
```

**Exemple avec format de date alternatif (YYYY/MM/DD) :**

```bash
curl -X POST "http://localhost:8000/agents/product_hunt_leaderboard/run" \
     -H "Content-Type: application/json" \
     -d '{
       "date": "2025/01/15",
       "max_products": 500
     }'
```

**Exemple pour le leaderboard d'aujourd'hui :**

```bash
# Remplacez la date par la date d'aujourd'hui
curl -X POST "http://localhost:8000/agents/product_hunt_leaderboard/run" \
     -H "Content-Type: application/json" \
     -d '{
       "date": "2025-01-20",
       "max_products": 1000
     }'
```

**Exemple minimal (seulement la date requise) :**

```bash
curl -X POST "http://localhost:8000/agents/product_hunt_leaderboard/run" \
     -H "Content-Type: application/json" \
     -d '{
       "date": "2025-01-15"
     }'
```

**Exemple avec Python :**

```python
import requests
from datetime import datetime, timedelta

# Leaderboard d'hier
yesterday = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")
response = requests.post(
    "http://localhost:8000/agents/product_hunt_leaderboard/run",
    json={
        "date": yesterday,
        "max_products": 1000,
        "output_path": f"ph_leaderboard_{yesterday}.json"
    }
)
leaderboard = response.json()
print(f"Produits extraits: {len(leaderboard['products'])}")
for product in leaderboard['products'][:5]:
    print(f"#{product.get('rank', 'N/A')} - {product['name']}: {product.get('upvotes', 0)} upvotes")
```

**Note importante :** La date est utilis√©e pour construire automatiquement l'URL du leaderboard Product Hunt au format `https://www.producthunt.com/leaderboard/daily/YYYY/MM/DD/all`. Vous n'avez pas besoin de fournir l'URL compl√®te, seulement la date.

**R√©ponse :** Rapport structur√© (`ProductHuntLeaderboardReport`) contenant :
- `source_url` : URL du leaderboard analys√©
- `products` : Liste des produits class√©s avec leurs m√©triques (nom, rang, description, tags, upvotes, maker, commentaires, etc.)

### 5. FutureTools Extractor (`futuretools_extractor`)

Agent sp√©cialis√© dans l'extraction d'outils depuis FutureTools. Optimis√© pour la structure sp√©cifique de FutureTools et utilise des strat√©gies d'extraction directe du HTML pour une meilleure performance.

**Endpoint :** `POST /agents/futuretools_extractor/run`

**Param√®tres :**
- `url` (optionnel, `AnyHttpUrl`, d√©faut: `"https://www.futuretools.io/newly-added"`) : URL de la page FutureTools √† analyser. La page `newly-added` est recommand√©e car elle contient tous les outils r√©cemment ajout√©s
- `max_tools` (optionnel, `int`, d√©faut: `1000`) : Nombre maximum d'outils √† capturer (min: 1, max: 10000). Utilisez un nombre √©lev√© comme 1000 pour extraire tous les outils disponibles
- `output_path` (optionnel, `Path`, d√©faut: `"futuretools_tools.json"`) : Chemin de destination pour le fichier JSON

**Exemple complet avec tous les param√®tres :**

```bash
curl -X POST "http://localhost:8000/agents/futuretools_extractor/run" \
     -H "Content-Type: application/json" \
     -d '{
       "url": "https://www.futuretools.io/newly-added",
       "max_tools": 1000,
       "output_path": "futuretools_tools.json"
     }'
```

**Exemple pour la page newly-added (recommand√©) :**

```bash
curl -X POST "http://localhost:8000/agents/futuretools_extractor/run" \
     -H "Content-Type: application/json" \
     -d '{
       "url": "https://www.futuretools.io/newly-added",
       "max_tools": 1000
     }'
```

**Exemple pour la page principale :**

```bash
curl -X POST "http://localhost:8000/agents/futuretools_extractor/run" \
     -H "Content-Type: application/json" \
     -d '{
       "url": "https://www.futuretools.io/",
       "max_tools": 500
     }'
```

**Exemple minimal (utilise les valeurs par d√©faut) :**

```bash
curl -X POST "http://localhost:8000/agents/futuretools_extractor/run" \
     -H "Content-Type: application/json" \
     -d '{
       "url": "https://www.futuretools.io/newly-added"
     }'
```

**Exemple avec Python :**

```python
import requests

# Extraction depuis la page newly-added (recommand√©)
response = requests.post(
    "http://localhost:8000/agents/futuretools_extractor/run",
    json={
        "url": "https://www.futuretools.io/newly-added",
        "max_tools": 1000,
        "output_path": "futuretools_tools.json"
    }
)

# V√©rifier le code de statut
if response.status_code == 200:
    report = response.json()
    print(f"‚úÖ Extraction r√©ussie!")
    print(f"Source: {report['source_url']}")
    print(f"Outils extraits: {len(report['tools'])}")
    
    # Afficher les premiers outils
    for i, tool in enumerate(report['tools'][:10], 1):
        print(f"\n{i}. {tool['name']}")
        print(f"   Cat√©gorie: {tool.get('category', 'N/A')}")
        print(f"   Description: {tool.get('description', 'N/A')[:100]}...")
        if tool.get('tool_url'):
            print(f"   URL: {tool['tool_url']}")
elif response.status_code == 206:
    data = response.json()
    print(f"‚ö†Ô∏è  Attention: {data.get('warning', 'Extraction partielle')}")
else:
    print(f"‚ùå Erreur {response.status_code}: {response.text}")
```

**Note importante :** Cet agent est sp√©cialement optimis√© pour FutureTools et utilise des strat√©gies d'extraction directe du HTML pour une meilleure performance. Pour d'autres sites, utilisez `startup_listing` ou `universal_startup_extractor`. La page `newly-added` est recommand√©e car elle contient tous les outils r√©cemment ajout√©s dans une structure coh√©rente.

**R√©ponse :** Rapport structur√© (`FutureToolsReport`) contenant :
- `source_url` : URL de la page FutureTools analys√©e
- `tools` : Liste des outils extraits avec :
  - `name` : Nom de l'outil
  - `tool_url` : URL de la page de l'outil si disponible
  - `category` : Cat√©gorie/tag de l'outil (ex: "Automation & Agents", "Productivity")
  - `description` : Description de l'outil si disponible

### 6. AppSumo Hot Extractor (`appsumo_hot_extractor`)

Agent sp√©cialis√© dans l'extraction de produits tendances depuis la collection "What's hot" d'AppSumo. Extrait les produits avec leurs prix, notes, badges et informations de cat√©gorie.

**Endpoint :** `POST /agents/appsumo_hot_extractor/run`

**Param√®tres :**
- `url` (optionnel, `AnyHttpUrl`, d√©faut: `"https://appsumo.com/collections/whats-hot/"`) : URL de la collection "What's hot" d'AppSumo
- `max_products` (optionnel, `int`, d√©faut: `200`) : Nombre maximum de produits √† capturer (min: 1, max: 2000)
- `output_path` (optionnel, `Path`, d√©faut: `"appsumo_hot_products.json"`) : Chemin de destination pour le fichier JSON

**Exemple complet :**

```bash
curl -X POST "http://localhost:8000/agents/appsumo_hot_extractor/run" \
     -H "Content-Type: application/json" \
     -d '{
       "url": "https://appsumo.com/collections/whats-hot/",
       "max_products": 200,
       "output_path": "appsumo_hot_products.json"
     }'
```

**Exemple minimal :**

```bash
curl -X POST "http://localhost:8000/agents/appsumo_hot_extractor/run" \
     -H "Content-Type: application/json" \
     -d '{}'
```

**Exemple avec Python :**

```python
import requests

response = requests.post(
    "http://localhost:8000/agents/appsumo_hot_extractor/run",
    json={
        "url": "https://appsumo.com/collections/whats-hot/",
        "max_products": 500
    }
)
report = response.json()
print(f"Produits extraits: {len(report['products'])}")
```

**R√©ponse :** Rapport structur√© (`AppSumoHotReport`) contenant les produits tendances avec leurs m√©tadonn√©es compl√®tes.

### 7. AppSumo New Extractor (`appsumo_new_extractor`)

Agent sp√©cialis√© dans l'extraction de nouveaux produits depuis la collection "New arrivals" d'AppSumo. Extrait les produits r√©cemment ajout√©s avec leurs prix, notes, badges et informations de cat√©gorie.

**Endpoint :** `POST /agents/appsumo_new_extractor/run`

**Param√®tres :**
- `url` (optionnel, `AnyHttpUrl`, d√©faut: `"https://appsumo.com/collections/new/"`) : URL de la collection "New arrivals" d'AppSumo
- `max_products` (optionnel, `int`, d√©faut: `200`) : Nombre maximum de produits √† capturer (min: 1, max: 2000)
- `output_path` (optionnel, `Path`, d√©faut: `"appsumo_new_products.json"`) : Chemin de destination pour le fichier JSON

**Exemple complet :**

```bash
curl -X POST "http://localhost:8000/agents/appsumo_new_extractor/run" \
     -H "Content-Type: application/json" \
     -d '{
       "url": "https://appsumo.com/collections/new/",
       "max_products": 200,
       "output_path": "appsumo_new_products.json"
     }'
```

**Exemple minimal :**

```bash
curl -X POST "http://localhost:8000/agents/appsumo_new_extractor/run" \
     -H "Content-Type: application/json" \
     -d '{}'
```

### 8. BetaList Extractor (`betalist_extractor`)

Agent sp√©cialis√© dans l'extraction de startups depuis BetaList. Extrait les startups r√©cemment publi√©es avec filtrage par date. Optimis√© pour le scroll infini de BetaList.

**Endpoint :** `POST /agents/betalist_extractor/run`

**Param√®tres :**
- `url` (optionnel, `AnyHttpUrl`, d√©faut: `"https://betalist.com/"`) : URL de la page BetaList
- `last_days` (optionnel, `int`, d√©faut: `3`) : Nombre de jours r√©cents √† conserver (min: 1, max: 30)
- `max_startups` (optionnel, `int`, d√©faut: `200`) : Nombre maximum de startups √† capturer (min: 1, max: 2000)
- `output_path` (optionnel, `Path`, d√©faut: `"betalist_recent.json"`) : Chemin de destination pour le fichier JSON

**Exemple complet :**

```bash
curl -X POST "http://localhost:8000/agents/betalist_extractor/run" \
     -H "Content-Type: application/json" \
     -d '{
       "url": "https://betalist.com/",
       "last_days": 7,
       "max_startups": 500,
       "output_path": "betalist_last_week.json"
     }'
```

**Exemple pour les startups de la derni√®re semaine :**

```bash
curl -X POST "http://localhost:8000/agents/betalist_extractor/run" \
     -H "Content-Type: application/json" \
     -d '{
       "last_days": 7,
       "max_startups": 1000
     }'
```

### 9. Station F Companies Extractor (`stationf_companies_extractor`)

Agent sp√©cialis√© dans l'extraction d'entreprises depuis Station F HAL (Hub & Accelerator). Extrait les entreprises avec leurs secteurs, stades, localisations et autres m√©tadonn√©es. Supporte l'authentification optionnelle pour acc√©der aux pages priv√©es.

**Endpoint :** `POST /agents/stationf_companies_extractor/run`

**Param√®tres :**
- `url` (optionnel, `str`, d√©faut: `"https://hal2.stationf.co/companies"`) : URL de la page des entreprises Station F
- `max_companies` (optionnel, `int`, d√©faut: `1000`) : Nombre maximum d'entreprises √† capturer (min: 1, max: 10000)
- `output_path` (optionnel, `Path`, d√©faut: `"stationf_companies.json"`) : Chemin de destination pour le fichier JSON
- `email` (optionnel, `str`) : Email pour l'authentification (si la page n√©cessite une connexion)
- `password` (optionnel, `str`) : Mot de passe pour l'authentification (si la page n√©cessite une connexion)

**Exemple sans authentification :**

```bash
curl -X POST "http://localhost:8000/agents/stationf_companies_extractor/run" \
     -H "Content-Type: application/json" \
     -d '{
       "url": "https://hal2.stationf.co/companies",
       "max_companies": 1000,
       "output_path": "stationf_companies.json"
     }'
```

**Exemple avec authentification :**

```bash
curl -X POST "http://localhost:8000/agents/stationf_companies_extractor/run" \
     -H "Content-Type: application/json" \
     -d '{
       "url": "https://hal2.stationf.co/companies",
       "max_companies": 1000,
       "email": "votre@email.com",
       "password": "votre_mot_de_passe",
       "output_path": "stationf_companies.json"
     }'
```

**Note importante :** Si la page n√©cessite une authentification, fournissez les param√®tres `email` et `password`. Sinon, l'agent tentera d'acc√©der √† la page publique si disponible.

### 10. Zone Secure Startups Extractor (`zone_secure_startups_extractor`)

Agent sp√©cialis√© dans l'extraction EXHAUSTIVE de startups depuis Zone Secure. Extrait toutes les startups de toutes les pages avec navigation multi-pages. G√®re la pagination et le filtrage des √©l√©ments de navigation.

**Endpoint :** `POST /agents/zone_secure_startups_extractor/run`

**Param√®tres :**
- `url` (optionnel, `str`, d√©faut: `"https://fr.zone-secure.net/20412/2540033/#page=1"`) : URL de la premi√®re page des startups Zone Secure
- `max_startups` (optionnel, `int`, d√©faut: `10000`) : Nombre maximum de startups √† capturer (min: 1, max: 50000)
- `output_path` (optionnel, `Path`, d√©faut: `"zone_secure_startups.json"`) : Chemin de destination pour le fichier JSON

**Exemple complet :**

```bash
curl -X POST "http://localhost:8000/agents/zone_secure_startups_extractor/run" \
     -H "Content-Type: application/json" \
     -d '{
       "url": "https://fr.zone-secure.net/20412/2540033/#page=1",
       "max_startups": 10000,
       "output_path": "zone_secure_startups.json"
     }'
```

**Exemple pour extraction limit√©e :**

```bash
curl -X POST "http://localhost:8000/agents/zone_secure_startups_extractor/run" \
     -H "Content-Type: application/json" \
     -d '{
       "max_startups": 100
     }'
```

**Note importante :** Cet agent est con√ßu pour extraire toutes les startups de toutes les pages. Il g√®re automatiquement la pagination et navigue entre les pages jusqu'√† atteindre la limite `max_startups` ou la fin du catalogue.

### 11. Airtable Extractor (`airtable_extractor`)

Agent sp√©cialis√© dans l'extraction de donn√©es depuis Airtable. Extrait les lignes et colonnes depuis une vue partag√©e Airtable. Utilise l'interception r√©seau pour r√©cup√©rer l'URL API automatiquement.

**Endpoint :** `POST /agents/airtable_extractor/run`

**Param√®tres :**
- `url` (requis, `str`) : URL de la vue partag√©e Airtable (format: `https://airtable.com/appXXX/shrXXX`) ou URL API compl√®te

**Exemple avec vue partag√©e :**

```bash
curl -X POST "http://localhost:8000/agents/airtable_extractor/run" \
     -H "Content-Type: application/json" \
     -d '{
       "url": "https://airtable.com/appXXXXXXXXXXXXXX/tblYYYYYYYYYYYYYY/viwZZZZZZZZZZZZZZ"
     }'
```

**Exemple avec endpoint API :**

```bash
curl -X POST "http://localhost:8000/agents/airtable_extractor/run" \
     -H "Content-Type: application/json" \
     -d '{
       "url": "https://api.airtable.com/v0/appXXXXXXXXXXXXXX/tblYYYYYYYYYYYYYY"
     }'
```

**Exemple avec Python :**

```python
import requests

response = requests.post(
    "http://localhost:8000/agents/airtable_extractor/run",
    json={
        "url": "https://airtable.com/appXXX/tblYYY/viwZZZ"
    }
)
data = response.json()
print(f"Colonnes: {len(data['columns'])}")
print(f"Lignes: {len(data['rows'])}")
```

**R√©ponse :** Rapport structur√© (`AirtableReport`) contenant :
- `metadata` : M√©tadonn√©es sur la source et les statistiques
- `columns` : Liste des colonnes avec leurs identifiants et noms
- `rows` : Liste des lignes avec toutes les donn√©es

**Note importante :** Si vous fournissez une vue partag√©e Airtable (URL publique), l'agent intercepte automatiquement les requ√™tes r√©seau pour r√©cup√©rer l'URL API et extraire les donn√©es. Pour les endpoints API directs, l'agent les utilise directement.

### R√©sum√© des agents sp√©cialis√©s

Tous les agents sp√©cialis√©s offrent :
- ‚úÖ **Performance optimale** : Extraction 2-3x plus rapide que les agents g√©n√©raux
- ‚úÖ **Fiabilit√© accrue** : Moins d'erreurs gr√¢ce √† une connaissance approfondie de la structure
- ‚úÖ **Donn√©es compl√®tes** : M√©tadonn√©es sp√©cifiques √† chaque plateforme
- ‚úÖ **Gestion avanc√©e** : Pagination, authentification, scroll infini automatiques

Pour toute autre plateforme non list√©e ci-dessus, utilisez l'agent `universal_startup_extractor` qui fonctionne avec n'importe quel site web.

---

## Endpoints g√©n√©raux

### Lister les agents

```bash
GET /agents
```

Retourne la liste de tous les agents disponibles avec leurs descriptions.

### Obtenir les m√©tadonn√©es d'un agent

```bash
GET /agents/{agent_name}
```

Retourne les informations d√©taill√©es d'un agent sp√©cifique (description, sch√©mas d'entr√©e/sortie).

### Healthcheck

```bash
GET /health
```

V√©rifie que l'API est op√©rationnelle et retourne le nombre d'agents disponibles.

## Documentation interactive

L'API expose une documentation interactive compl√®te avec des exemples :

- **Swagger UI** : `http://localhost:8000/docs` - Interface interactive pour tester tous les endpoints
- **ReDoc** : `http://localhost:8000/redoc` - Documentation alternative avec une pr√©sentation √©l√©gante

Chaque endpoint POST contient plusieurs exemples pr√©-configur√©s que vous pouvez tester directement depuis l'interface Swagger.

## Structure des r√©ponses

Tous les endpoints POST retournent des rapports structur√©s au format JSON avec des sch√©mas Pydantic valid√©s. Les erreurs sont retourn√©es avec des codes HTTP appropri√©s :

- `200` : Succ√®s - Rapport g√©n√©r√© avec succ√®s
- `206` : Contenu partiel - L'agent a √©t√© interrompu avant de finaliser l'extraction. La r√©ponse contient un rapport de fallback avec un champ `warning` expliquant le probl√®me. V√©rifiez les logs du serveur pour plus de d√©tails.
- `400` : Requ√™te invalide (payload mal form√©, param√®tres invalides)
- `404` : Agent introuvable
- `500` : Erreur interne lors de l'ex√©cution de l'agent

### Gestion des rapports de fallback

Si un agent est interrompu avant de finaliser l'extraction (timeout, erreur, etc.), l'API retourne un code `206` (Partial Content) avec une structure de r√©ponse enrichie :

```json
{
  "report": {
    "source_url": "...",
    "startups": [{"name": "Informations indisponibles", ...}]
  },
  "warning": "L'agent a √©t√© interrompu avant de finaliser l'extraction...",
  "success": false,
  "message": "V√©rifiez les logs du serveur pour plus de d√©tails..."
}
```

**Causes possibles d'un rapport de fallback :**
- Timeout de l'agent (page trop lente √† charger, trop de contenu)
- Erreur de parsing JSON par le LLM
- Probl√®me de connexion ou de chargement de la page
- Configuration LLM incorrecte (cl√© API manquante ou invalide)

**Solutions :**
1. V√©rifiez les logs du serveur pour identifier la cause exacte
2. V√©rifiez que les variables d'environnement LLM sont correctement configur√©es (`BROWSER_USE_API_KEY` ou `OPENAI_API_KEY`)
3. R√©essayez avec une URL plus simple ou une limite plus faible
4. Augmentez les timeouts si n√©cessaire (configuration dans le code de l'agent)

## Personnalisation

Pour ajouter un nouvel agent √† l'API :

1. Importez les classes Input, Report et la fonction `run_*` de votre agent
2. Enregistrez l'agent dans le registre :

```python
from examples.histia.fastapi_agents import registry
from examples.histia.votre_agent import (
    VotreAgentInput,
    VotreAgentReport,
    run_votre_agent,
)

registry.register(
    name='votre_agent',
    description='Description de votre agent',
    input_class=VotreAgentInput,
    output_class=VotreAgentReport,
    run_function=run_votre_agent,
)
```

L'endpoint sera automatiquement cr√©√© √† `/agents/votre_agent/run`.

## Notes importantes

- Les agents utilisent `browser-use` pour l'automation web et peuvent prendre plusieurs minutes selon la complexit√© de la t√¢che
- Les timeouts sont configur√©s pour chaque agent selon ses besoins (g√©n√©ralement 300s pour step_timeout, 180s pour llm_timeout)
- Les rapports sont valid√©s avec Pydantic pour garantir la coh√©rence des donn√©es
- En cas d'√©chec partiel, les agents retournent des rapports de fallback (code 206) plut√¥t que d'√©chouer compl√®tement
- **Important** : V√©rifiez toujours le code de statut HTTP dans vos clients :
  - `200` = Succ√®s complet
  - `206` = Rapport de fallback (agent interrompu, v√©rifiez les logs)
  - `400` = Requ√™te invalide
  - `500` = Erreur serveur

### D√©pannage des erreurs d'extraction

Si vous recevez des rapports de fallback (code 206) :

1. **V√©rifiez les variables d'environnement** :
   ```bash
   # Pour ChatBrowserUse (recommand√©)
   export BROWSER_USE_API_KEY="votre_cl√©"
   
   # Ou pour OpenAI/LiteLLM
   export OPENAI_API_KEY="votre_cl√©"
   export OPENAI_API_BASE="https://votre-endpoint.com"  # Si n√©cessaire
   ```

2. **V√©rifiez les logs du serveur** : Les agents affichent des messages d√©taill√©s sur la console o√π l'API est lanc√©e

3. **R√©duisez la complexit√©** :
   - Utilisez des limites plus faibles (`max_startups`, `max_products`)
   - Testez avec des URLs plus simples d'abord
   - V√©rifiez que l'URL est accessible et contient bien du contenu

4. **V√©rifiez la connectivit√©** : Assurez-vous que le serveur peut acc√©der aux URLs cibles (pas de firewall, proxy, etc.)
